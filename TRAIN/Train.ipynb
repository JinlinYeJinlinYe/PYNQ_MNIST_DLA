{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b621f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 20, training accuracy 0.18\n",
      "step 40, training accuracy 0.52\n",
      "step 60, training accuracy 0.44\n",
      "step 80, training accuracy 0.56\n",
      "step 100, training accuracy 0.56\n",
      "step 120, training accuracy 0.74\n",
      "step 140, training accuracy 0.64\n",
      "step 160, training accuracy 0.54\n",
      "step 180, training accuracy 0.58\n",
      "step 200, training accuracy 0.74\n",
      "step 220, training accuracy 0.58\n",
      "step 240, training accuracy 0.72\n",
      "step 260, training accuracy 0.7\n",
      "step 280, training accuracy 0.78\n",
      "step 300, training accuracy 0.72\n",
      "step 320, training accuracy 0.82\n",
      "step 340, training accuracy 0.8\n",
      "step 360, training accuracy 0.82\n",
      "step 380, training accuracy 0.88\n",
      "step 400, training accuracy 0.88\n",
      "step 420, training accuracy 0.9\n",
      "step 440, training accuracy 0.8\n",
      "step 460, training accuracy 0.88\n",
      "step 480, training accuracy 0.76\n",
      "step 500, training accuracy 0.82\n",
      "step 520, training accuracy 0.74\n",
      "step 540, training accuracy 0.78\n",
      "step 560, training accuracy 0.84\n",
      "step 580, training accuracy 0.86\n",
      "step 600, training accuracy 0.92\n",
      "step 620, training accuracy 0.86\n",
      "step 640, training accuracy 0.88\n",
      "step 660, training accuracy 0.92\n",
      "step 680, training accuracy 0.9\n",
      "step 700, training accuracy 0.9\n",
      "step 720, training accuracy 0.86\n",
      "step 740, training accuracy 0.88\n",
      "step 760, training accuracy 0.82\n",
      "step 780, training accuracy 0.94\n",
      "step 800, training accuracy 0.84\n",
      "step 820, training accuracy 0.86\n",
      "step 840, training accuracy 0.84\n",
      "step 860, training accuracy 0.94\n",
      "step 880, training accuracy 0.78\n",
      "step 900, training accuracy 0.88\n",
      "step 920, training accuracy 0.92\n",
      "step 940, training accuracy 0.88\n",
      "step 960, training accuracy 0.84\n",
      "step 980, training accuracy 0.86\n",
      "step 1000, training accuracy 0.92\n",
      "step 1020, training accuracy 0.9\n",
      "step 1040, training accuracy 0.94\n",
      "step 1060, training accuracy 0.96\n",
      "step 1080, training accuracy 0.98\n",
      "step 1100, training accuracy 0.92\n",
      "step 1120, training accuracy 0.94\n",
      "step 1140, training accuracy 0.9\n",
      "step 1160, training accuracy 0.88\n",
      "step 1180, training accuracy 0.92\n",
      "step 1200, training accuracy 0.9\n",
      "step 1220, training accuracy 0.84\n",
      "step 1240, training accuracy 0.94\n",
      "step 1260, training accuracy 0.84\n",
      "step 1280, training accuracy 0.9\n",
      "step 1300, training accuracy 0.86\n",
      "step 1320, training accuracy 0.88\n",
      "step 1340, training accuracy 0.78\n",
      "step 1360, training accuracy 0.9\n",
      "step 1380, training accuracy 0.84\n",
      "step 1400, training accuracy 0.92\n",
      "step 1420, training accuracy 0.92\n",
      "step 1440, training accuracy 0.94\n",
      "step 1460, training accuracy 0.94\n",
      "step 1480, training accuracy 0.94\n",
      "step 1500, training accuracy 0.9\n",
      "step 1520, training accuracy 0.94\n",
      "step 1540, training accuracy 0.94\n",
      "step 1560, training accuracy 0.94\n",
      "step 1580, training accuracy 0.88\n",
      "step 1600, training accuracy 0.9\n",
      "step 1620, training accuracy 0.86\n",
      "step 1640, training accuracy 0.96\n",
      "step 1660, training accuracy 0.96\n",
      "step 1680, training accuracy 0.94\n",
      "step 1700, training accuracy 0.9\n",
      "step 1720, training accuracy 0.94\n",
      "step 1740, training accuracy 0.94\n",
      "step 1760, training accuracy 0.84\n",
      "step 1780, training accuracy 0.88\n",
      "step 1800, training accuracy 0.9\n",
      "step 1820, training accuracy 0.84\n",
      "step 1840, training accuracy 0.9\n",
      "step 1860, training accuracy 0.88\n",
      "step 1880, training accuracy 0.92\n",
      "step 1900, training accuracy 0.88\n",
      "step 1920, training accuracy 0.94\n",
      "step 1940, training accuracy 0.96\n",
      "step 1960, training accuracy 0.86\n",
      "step 1980, training accuracy 0.96\n",
      "step 2000, training accuracy 0.92\n",
      "step 2020, training accuracy 0.9\n",
      "step 2040, training accuracy 0.9\n",
      "step 2060, training accuracy 0.92\n",
      "step 2080, training accuracy 0.92\n",
      "step 2100, training accuracy 0.96\n",
      "step 2120, training accuracy 0.92\n",
      "step 2140, training accuracy 0.92\n",
      "step 2160, training accuracy 0.94\n",
      "step 2180, training accuracy 0.88\n",
      "step 2200, training accuracy 0.9\n",
      "step 2220, training accuracy 0.94\n",
      "step 2240, training accuracy 0.88\n",
      "step 2260, training accuracy 0.88\n",
      "step 2280, training accuracy 0.9\n",
      "step 2300, training accuracy 0.92\n",
      "step 2320, training accuracy 0.96\n",
      "step 2340, training accuracy 0.96\n",
      "step 2360, training accuracy 0.94\n",
      "step 2380, training accuracy 0.86\n",
      "step 2400, training accuracy 0.96\n",
      "step 2420, training accuracy 0.94\n",
      "step 2440, training accuracy 0.96\n",
      "step 2460, training accuracy 0.96\n",
      "step 2480, training accuracy 0.92\n",
      "step 2500, training accuracy 0.94\n",
      "step 2520, training accuracy 0.96\n",
      "step 2540, training accuracy 0.98\n",
      "step 2560, training accuracy 0.96\n",
      "step 2580, training accuracy 1\n",
      "step 2600, training accuracy 0.96\n",
      "step 2620, training accuracy 0.96\n",
      "step 2640, training accuracy 0.9\n",
      "step 2660, training accuracy 0.92\n",
      "step 2680, training accuracy 0.98\n",
      "step 2700, training accuracy 0.98\n",
      "step 2720, training accuracy 0.92\n",
      "step 2740, training accuracy 1\n",
      "step 2760, training accuracy 0.92\n",
      "step 2780, training accuracy 0.92\n",
      "step 2800, training accuracy 0.94\n",
      "step 2820, training accuracy 0.96\n",
      "step 2840, training accuracy 0.96\n",
      "step 2860, training accuracy 0.9\n",
      "step 2880, training accuracy 0.96\n",
      "step 2900, training accuracy 0.96\n",
      "step 2920, training accuracy 0.98\n",
      "step 2940, training accuracy 0.94\n",
      "step 2960, training accuracy 0.9\n",
      "step 2980, training accuracy 0.94\n",
      "step 3000, training accuracy 0.94\n",
      "step 3020, training accuracy 0.98\n",
      "step 3040, training accuracy 0.94\n",
      "step 3060, training accuracy 0.98\n",
      "step 3080, training accuracy 0.94\n",
      "step 3100, training accuracy 0.94\n",
      "step 3120, training accuracy 0.96\n",
      "step 3140, training accuracy 0.98\n",
      "step 3160, training accuracy 0.96\n",
      "step 3180, training accuracy 0.96\n",
      "step 3200, training accuracy 1\n",
      "step 3220, training accuracy 0.96\n",
      "step 3240, training accuracy 1\n",
      "step 3260, training accuracy 0.98\n",
      "step 3280, training accuracy 0.9\n",
      "step 3300, training accuracy 0.9\n",
      "step 3320, training accuracy 1\n",
      "step 3340, training accuracy 0.94\n",
      "step 3360, training accuracy 0.9\n",
      "step 3380, training accuracy 0.98\n",
      "step 3400, training accuracy 0.9\n",
      "step 3420, training accuracy 0.94\n",
      "step 3440, training accuracy 1\n",
      "step 3460, training accuracy 0.98\n",
      "step 3480, training accuracy 1\n",
      "step 3500, training accuracy 0.94\n",
      "step 3520, training accuracy 0.9\n",
      "step 3540, training accuracy 0.9\n",
      "step 3560, training accuracy 0.96\n",
      "step 3580, training accuracy 0.98\n",
      "step 3600, training accuracy 0.96\n",
      "step 3620, training accuracy 1\n",
      "step 3640, training accuracy 0.98\n",
      "step 3660, training accuracy 0.92\n",
      "step 3680, training accuracy 0.96\n",
      "step 3700, training accuracy 0.98\n",
      "step 3720, training accuracy 0.96\n",
      "step 3740, training accuracy 1\n",
      "step 3760, training accuracy 0.9\n",
      "step 3780, training accuracy 0.9\n",
      "step 3800, training accuracy 0.96\n",
      "step 3820, training accuracy 0.98\n",
      "step 3840, training accuracy 0.98\n",
      "step 3860, training accuracy 0.98\n",
      "step 3880, training accuracy 1\n",
      "step 3900, training accuracy 0.9\n",
      "step 3920, training accuracy 0.92\n",
      "step 3940, training accuracy 0.92\n",
      "step 3960, training accuracy 0.98\n",
      "step 3980, training accuracy 0.96\n",
      "step 4000, training accuracy 0.96\n",
      "step 4020, training accuracy 0.96\n",
      "step 4040, training accuracy 0.96\n",
      "step 4060, training accuracy 0.94\n",
      "step 4080, training accuracy 0.92\n",
      "step 4100, training accuracy 1\n",
      "step 4120, training accuracy 0.98\n",
      "step 4140, training accuracy 1\n",
      "step 4160, training accuracy 0.96\n",
      "step 4180, training accuracy 0.94\n",
      "step 4200, training accuracy 0.96\n",
      "step 4220, training accuracy 0.98\n",
      "step 4240, training accuracy 0.92\n",
      "step 4260, training accuracy 0.96\n",
      "step 4280, training accuracy 0.92\n",
      "step 4300, training accuracy 0.98\n",
      "step 4320, training accuracy 0.94\n",
      "step 4340, training accuracy 0.98\n",
      "step 4360, training accuracy 1\n",
      "step 4380, training accuracy 0.96\n",
      "step 4400, training accuracy 0.98\n",
      "step 4420, training accuracy 1\n",
      "step 4440, training accuracy 0.92\n",
      "step 4460, training accuracy 1\n",
      "step 4480, training accuracy 0.92\n",
      "step 4500, training accuracy 1\n",
      "step 4520, training accuracy 0.98\n",
      "step 4540, training accuracy 0.94\n",
      "step 4560, training accuracy 1\n",
      "step 4580, training accuracy 0.98\n",
      "step 4600, training accuracy 0.94\n",
      "step 4620, training accuracy 0.94\n",
      "step 4640, training accuracy 1\n",
      "step 4660, training accuracy 0.96\n",
      "step 4680, training accuracy 1\n",
      "step 4700, training accuracy 0.98\n",
      "step 4720, training accuracy 0.94\n",
      "step 4740, training accuracy 0.96\n",
      "step 4760, training accuracy 0.98\n",
      "step 4780, training accuracy 0.98\n",
      "step 4800, training accuracy 0.92\n",
      "step 4820, training accuracy 0.98\n",
      "step 4840, training accuracy 0.96\n",
      "step 4860, training accuracy 0.9\n",
      "step 4880, training accuracy 0.98\n",
      "step 4900, training accuracy 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4920, training accuracy 0.92\n",
      "step 4940, training accuracy 0.96\n",
      "step 4960, training accuracy 0.94\n",
      "step 4980, training accuracy 0.96\n",
      "test accuracy 0.9667\n",
      "Recording tensor W_conv1 ...\n",
      "Recording tensor b_conv1 ...\n",
      "Recording tensor W_conv2 ...\n",
      "Recording tensor b_conv2 ...\n",
      "Recording tensor W_fc1 ...\n",
      "Recording tensor b_fc1 ...\n",
      "Recording tensor W_fc2 ...\n",
      "Recording tensor b_fc2 ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "def Record_Tensor(tensor,name):\n",
    "\tprint (\"Recording tensor \"+name+\" ...\")\n",
    "\tf = open('./record/'+name+'.dat', 'w')\n",
    "\tarray=tensor.eval()\n",
    "\t#print (\"The range: [\"+str(np.min(array))+\":\"+str(np.max(array))+\"]\")\n",
    "\tif(np.size(np.shape(array))==1):\n",
    "\t\tRecord_Array1D(array,name,f)\n",
    "\telse:\n",
    "\t\tif(np.size(np.shape(array))==2):\n",
    "\t\t\tRecord_Array2D(array,name,f)\n",
    "\t\telse:\n",
    "\t\t\tif(np.size(np.shape(array))==3):\n",
    "\t\t\t\tRecord_Array3D(array,name,f)\n",
    "\t\t\telse:\n",
    "\t\t\t\tRecord_Array4D(array,name,f)\n",
    "\tf.close()\n",
    "\n",
    "def Record_Array1D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tf.write(str(array[i])+\"\\n\")\n",
    "\n",
    "def Record_Array2D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tfor j in range(np.shape(array)[1]):\n",
    "\t\t\tf.write(str(array[i][j])+\"\\n\")\n",
    "\n",
    "def Record_Array3D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tfor j in range(np.shape(array)[1]):\n",
    "\t\t\tfor k in range(np.shape(array)[2]):\n",
    "\t\t\t\tf.write(str(array[i][j][k])+\"\\n\")\n",
    "\n",
    "def Record_Array4D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tfor j in range(np.shape(array)[1]):\n",
    "\t\t\tfor k in range(np.shape(array)[2]):\n",
    "\t\t\t\tfor l in range(np.shape(array)[3]):\n",
    "\t\t\t\t\tf.write(str(array[i][j][k][l])+\"\\n\")\n",
    "\n",
    "with tf.name_scope('input'): \n",
    "\tx = tf.placeholder(\"float\", shape=[None, 784])\n",
    "\ty_ = tf.placeholder(\"float\", shape=[None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "\tinitial = tf.compat.v1.truncated_normal(shape, stddev=0.1);\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "\tinitial = tf.constant(0.1, shape=shape)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "\treturn tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2,1], padding='SAME')\n",
    "\n",
    "#First Convolutional Layer\n",
    "with tf.name_scope('1st_CNN'): \n",
    "\tW_conv1 = weight_variable([3, 3, 1, 16])\n",
    "\tb_conv1 = bias_variable([16])\n",
    "\tx_image = tf.reshape(x, [-1,28,28,1])\n",
    "\th_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\th_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#Second Convolutional Layer\n",
    "with tf.name_scope('2rd_CNN'): \n",
    "\tW_conv2 = weight_variable([3, 3, 16, 32])\n",
    "\tb_conv2 = bias_variable([32])\n",
    "\th_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\th_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#Densely Connected Layer\n",
    "with tf.name_scope('Densely_NN'): \n",
    "\tW_fc1 = weight_variable([ 7* 7* 32, 128])\n",
    "\tb_fc1 = bias_variable([128])\n",
    "\th_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*32])\n",
    "\th_fc1=tf.nn.relu(tf.matmul(h_pool2_flat , W_fc1) + b_fc1)\n",
    "\n",
    "#Dropout\n",
    "with tf.name_scope('Dropout'):\n",
    "\tkeep_prob = tf.placeholder(\"float\")\n",
    "\th_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#Readout Layer\n",
    "with tf.name_scope('Softmax'):\n",
    "\tW_fc2 = weight_variable([128, 10])\n",
    "\tb_fc2 = bias_variable([10])\n",
    "\ty_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "\tcross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "with tf.name_scope('Train'):\n",
    "\ttrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "\tcorrect_prediction = tf.equal(tf.argmax(y_conv ,1), tf.argmax(y_,1))\n",
    "\taccuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\"))\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"logs/\",sess.graph) \n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "for i in range(5000):\n",
    "\tbatch = mnist.train.next_batch(50);\n",
    "\tif i%20 == 0:\n",
    "\t\ttrain_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob:1.0});\n",
    "\t\tprint(\"step %d, training accuracy %g\"%(i, train_accuracy));\n",
    "\ttrain_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob:0.5});\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "Record_Tensor(W_conv1,\"W_conv1\")\n",
    "Record_Tensor(b_conv1,\"b_conv1\")\n",
    "Record_Tensor(W_conv2,\"W_conv2\")\n",
    "Record_Tensor(b_conv2,\"b_conv2\")\n",
    "Record_Tensor(W_fc1,\"W_fc1\")\n",
    "Record_Tensor(b_fc1,\"b_fc1\")\n",
    "Record_Tensor(W_fc2,\"W_fc2\")\n",
    "Record_Tensor(b_fc2,\"b_fc2\")\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc24b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
