{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b621f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-1-39ef2684fb24>:89: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\JinlinYE\\anaconda3\\envs\\tensorflow14\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0, training accuracy 0.08\n",
      "step 20, training accuracy 0.16\n",
      "step 40, training accuracy 0.16\n",
      "step 60, training accuracy 0.32\n",
      "step 80, training accuracy 0.48\n",
      "step 100, training accuracy 0.6\n",
      "step 120, training accuracy 0.66\n",
      "step 140, training accuracy 0.66\n",
      "step 160, training accuracy 0.6\n",
      "step 180, training accuracy 0.76\n",
      "step 200, training accuracy 0.76\n",
      "step 220, training accuracy 0.6\n",
      "step 240, training accuracy 0.84\n",
      "step 260, training accuracy 0.82\n",
      "step 280, training accuracy 0.78\n",
      "step 300, training accuracy 0.8\n",
      "step 320, training accuracy 0.78\n",
      "step 340, training accuracy 0.9\n",
      "step 360, training accuracy 0.86\n",
      "step 380, training accuracy 0.82\n",
      "step 400, training accuracy 0.88\n",
      "step 420, training accuracy 0.92\n",
      "step 440, training accuracy 0.92\n",
      "step 460, training accuracy 0.96\n",
      "step 480, training accuracy 0.84\n",
      "step 500, training accuracy 0.84\n",
      "step 520, training accuracy 0.8\n",
      "step 540, training accuracy 0.82\n",
      "step 560, training accuracy 0.86\n",
      "step 580, training accuracy 0.86\n",
      "step 600, training accuracy 0.96\n",
      "step 620, training accuracy 0.88\n",
      "step 640, training accuracy 0.9\n",
      "step 660, training accuracy 0.94\n",
      "step 680, training accuracy 0.92\n",
      "step 700, training accuracy 0.88\n",
      "step 720, training accuracy 0.9\n",
      "step 740, training accuracy 0.84\n",
      "step 760, training accuracy 0.86\n",
      "step 780, training accuracy 0.96\n",
      "step 800, training accuracy 0.8\n",
      "step 820, training accuracy 0.8\n",
      "step 840, training accuracy 0.86\n",
      "step 860, training accuracy 0.9\n",
      "step 880, training accuracy 0.8\n",
      "step 900, training accuracy 0.98\n",
      "step 920, training accuracy 0.92\n",
      "step 940, training accuracy 0.92\n",
      "step 960, training accuracy 0.84\n",
      "step 980, training accuracy 0.84\n",
      "step 1000, training accuracy 0.9\n",
      "step 1020, training accuracy 0.96\n",
      "step 1040, training accuracy 0.92\n",
      "step 1060, training accuracy 0.94\n",
      "step 1080, training accuracy 0.96\n",
      "step 1100, training accuracy 0.98\n",
      "step 1120, training accuracy 0.94\n",
      "step 1140, training accuracy 0.9\n",
      "step 1160, training accuracy 0.9\n",
      "step 1180, training accuracy 0.94\n",
      "step 1200, training accuracy 0.82\n",
      "step 1220, training accuracy 0.96\n",
      "step 1240, training accuracy 0.9\n",
      "step 1260, training accuracy 0.9\n",
      "step 1280, training accuracy 0.88\n",
      "step 1300, training accuracy 0.96\n",
      "step 1320, training accuracy 0.88\n",
      "step 1340, training accuracy 0.96\n",
      "step 1360, training accuracy 0.8\n",
      "step 1380, training accuracy 0.86\n",
      "step 1400, training accuracy 0.92\n",
      "step 1420, training accuracy 0.92\n",
      "step 1440, training accuracy 0.96\n",
      "step 1460, training accuracy 0.92\n",
      "step 1480, training accuracy 0.96\n",
      "step 1500, training accuracy 0.92\n",
      "step 1520, training accuracy 0.9\n",
      "step 1540, training accuracy 0.96\n",
      "step 1560, training accuracy 0.94\n",
      "step 1580, training accuracy 0.9\n",
      "step 1600, training accuracy 0.98\n",
      "step 1620, training accuracy 0.92\n",
      "step 1640, training accuracy 0.94\n",
      "step 1660, training accuracy 0.9\n",
      "step 1680, training accuracy 0.92\n",
      "step 1700, training accuracy 0.88\n",
      "step 1720, training accuracy 0.96\n",
      "step 1740, training accuracy 0.92\n",
      "step 1760, training accuracy 0.92\n",
      "step 1780, training accuracy 0.92\n",
      "step 1800, training accuracy 0.92\n",
      "step 1820, training accuracy 0.96\n",
      "step 1840, training accuracy 0.86\n",
      "step 1860, training accuracy 0.92\n",
      "step 1880, training accuracy 0.98\n",
      "step 1900, training accuracy 1\n",
      "step 1920, training accuracy 0.94\n",
      "step 1940, training accuracy 0.94\n",
      "step 1960, training accuracy 0.94\n",
      "step 1980, training accuracy 0.96\n",
      "step 2000, training accuracy 0.94\n",
      "step 2020, training accuracy 0.98\n",
      "step 2040, training accuracy 0.9\n",
      "step 2060, training accuracy 0.96\n",
      "step 2080, training accuracy 0.98\n",
      "step 2100, training accuracy 0.96\n",
      "step 2120, training accuracy 0.94\n",
      "step 2140, training accuracy 0.96\n",
      "step 2160, training accuracy 0.94\n",
      "step 2180, training accuracy 0.96\n",
      "step 2200, training accuracy 0.88\n",
      "step 2220, training accuracy 0.84\n",
      "step 2240, training accuracy 0.96\n",
      "step 2260, training accuracy 0.94\n",
      "step 2280, training accuracy 0.96\n",
      "step 2300, training accuracy 0.92\n",
      "step 2320, training accuracy 1\n",
      "step 2340, training accuracy 0.96\n",
      "step 2360, training accuracy 0.98\n",
      "step 2380, training accuracy 0.96\n",
      "step 2400, training accuracy 0.98\n",
      "step 2420, training accuracy 0.96\n",
      "step 2440, training accuracy 0.96\n",
      "step 2460, training accuracy 0.92\n",
      "step 2480, training accuracy 1\n",
      "step 2500, training accuracy 1\n",
      "step 2520, training accuracy 0.94\n",
      "step 2540, training accuracy 0.96\n",
      "step 2560, training accuracy 0.94\n",
      "step 2580, training accuracy 0.96\n",
      "step 2600, training accuracy 0.94\n",
      "step 2620, training accuracy 0.92\n",
      "step 2640, training accuracy 0.98\n",
      "step 2660, training accuracy 0.94\n",
      "step 2680, training accuracy 0.96\n",
      "step 2700, training accuracy 0.96\n",
      "step 2720, training accuracy 0.96\n",
      "step 2740, training accuracy 0.98\n",
      "step 2760, training accuracy 0.98\n",
      "step 2780, training accuracy 0.96\n",
      "step 2800, training accuracy 0.94\n",
      "step 2820, training accuracy 0.9\n",
      "step 2840, training accuracy 0.96\n",
      "step 2860, training accuracy 0.98\n",
      "step 2880, training accuracy 0.98\n",
      "step 2900, training accuracy 0.96\n",
      "step 2920, training accuracy 0.94\n",
      "step 2940, training accuracy 0.94\n",
      "step 2960, training accuracy 0.94\n",
      "step 2980, training accuracy 0.98\n",
      "test accuracy 0.9593\n",
      "Recording tensor W_conv1 ...\n",
      "Recording tensor b_conv1 ...\n",
      "Recording tensor W_conv2 ...\n",
      "Recording tensor b_conv2 ...\n",
      "Recording tensor W_fc1 ...\n",
      "Recording tensor b_fc1 ...\n",
      "Recording tensor W_fc2 ...\n",
      "Recording tensor b_fc2 ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "def Record_Tensor(tensor,name):\n",
    "\tprint (\"Recording tensor \"+name+\" ...\")\n",
    "\tf = open('./record/'+name+'.dat', 'w')\n",
    "\tarray=tensor.eval()\n",
    "\t#print (\"The range: [\"+str(np.min(array))+\":\"+str(np.max(array))+\"]\")\n",
    "\tif(np.size(np.shape(array))==1):\n",
    "\t\tRecord_Array1D(array,name,f)\n",
    "\telse:\n",
    "\t\tif(np.size(np.shape(array))==2):\n",
    "\t\t\tRecord_Array2D(array,name,f)\n",
    "\t\telse:\n",
    "\t\t\tif(np.size(np.shape(array))==3):\n",
    "\t\t\t\tRecord_Array3D(array,name,f)\n",
    "\t\t\telse:\n",
    "\t\t\t\tRecord_Array4D(array,name,f)\n",
    "\tf.close()\n",
    "\n",
    "def Record_Array1D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tf.write(str(array[i])+\"\\n\")\n",
    "\n",
    "def Record_Array2D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tfor j in range(np.shape(array)[1]):\n",
    "\t\t\tf.write(str(array[i][j])+\"\\n\")\n",
    "\n",
    "def Record_Array3D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tfor j in range(np.shape(array)[1]):\n",
    "\t\t\tfor k in range(np.shape(array)[2]):\n",
    "\t\t\t\tf.write(str(array[i][j][k])+\"\\n\")\n",
    "\n",
    "def Record_Array4D(array,name,f):\n",
    "\tfor i in range(np.shape(array)[0]):\n",
    "\t\tfor j in range(np.shape(array)[1]):\n",
    "\t\t\tfor k in range(np.shape(array)[2]):\n",
    "\t\t\t\tfor l in range(np.shape(array)[3]):\n",
    "\t\t\t\t\tf.write(str(array[i][j][k][l])+\"\\n\")\n",
    "\n",
    "with tf.name_scope('input'): \n",
    "\tx = tf.placeholder(\"float\", shape=[None, 784])\n",
    "\ty_ = tf.placeholder(\"float\", shape=[None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "\tinitial = tf.truncated_normal(shape, stddev=0.1)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "\tinitial = tf.constant(0.1, shape=shape)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "\treturn tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2,1], padding='VALID')\n",
    "\n",
    "#First Convolutional Layer\n",
    "with tf.name_scope('1st_CNN'): \n",
    "\tW_conv1 = weight_variable([5, 5, 1, 16]) #1代表维度输入维度是1 卷积核 5*5*16\n",
    "\tb_conv1 = bias_variable([16]) #偏置 16\n",
    "\tx_image = tf.reshape(x, [-1,28,28,1]) #输入图像28*28\n",
    "\th_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) #卷积运算后再激活 24*24*16\n",
    "\th_pool1 = max_pool_2x2(h_conv1) #池化运算 12*12*16\n",
    "\n",
    "#Second Convolutional Layer\n",
    "with tf.name_scope('2rd_CNN'): \n",
    "\tW_conv2 = weight_variable([5, 5, 16, 32]) #卷积核5*5*32 输入维度是16\n",
    "\tb_conv2 = bias_variable([32]) #偏置 32\n",
    "\th_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) #卷积运算后再激活  8*8*32\n",
    "\th_pool2 = max_pool_2x2(h_conv2) #池化运算 4*4*32\n",
    "\n",
    "#Densely Connected Layer\n",
    "with tf.name_scope('Densely_NN'): \n",
    "\tW_fc1 = weight_variable([ 4* 4* 32, 128]) #输入节点4*4*32 输出节点数128\n",
    "\tb_fc1 = bias_variable([128]) #偏置\n",
    "\th_pool2_flat = tf.reshape(h_pool2, [-1, 4*4*32]) #把最后的池化层的输出扁平化为1维\n",
    "\th_fc1=tf.nn.relu(tf.matmul(h_pool2_flat , W_fc1) + b_fc1) #求第一个全连接层的输出\n",
    "\n",
    "#Dropout\n",
    "with tf.name_scope('Dropout'):\n",
    "\tkeep_prob = tf.placeholder(\"float\")\n",
    "\th_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) #进行dropout处理 防止过拟合\n",
    "\n",
    "#Readout Layer\n",
    "with tf.name_scope('Softmax'):\n",
    "\tW_fc2 = weight_variable([128, 10])\n",
    "\tb_fc2 = bias_variable([10])\n",
    "\ty_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) #最后softmax\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "\tcross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "with tf.name_scope('Train'):\n",
    "\ttrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "\tcorrect_prediction = tf.equal(tf.argmax(y_conv ,1), tf.argmax(y_,1))\n",
    "\taccuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\"))\n",
    "\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "for i in range(3000):\n",
    "\tbatch = mnist.train.next_batch(50)\n",
    "\tif i%20 == 0:\n",
    "\t\ttrain_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob:1.0})\n",
    "\t\tprint(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\ttrain_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob:0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "Record_Tensor(W_conv1,\"W_conv1\")\n",
    "Record_Tensor(b_conv1,\"b_conv1\")\n",
    "Record_Tensor(W_conv2,\"W_conv2\")\n",
    "Record_Tensor(b_conv2,\"b_conv2\")\n",
    "Record_Tensor(W_fc1,\"W_fc1\")\n",
    "Record_Tensor(b_fc1,\"b_fc1\")\n",
    "Record_Tensor(W_fc2,\"W_fc2\")\n",
    "Record_Tensor(b_fc2,\"b_fc2\")\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc24b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
